#!/usr/bin/env python3
"""
Test Advanced Mathematical Extensions

Tests the implemented advanced extensions for computational efficiency
and mathematical correctness.
"""

import torch
import numpy as np
import sys
import os
import time

# Add src to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from src.core.meta_polytope_matrioshka import MetaPolytopeMatrioshka, BoundaryState
from src.core.sparse_higher_order_tensors import SparseHigherOrderTensorDynamics
from src.core.quantum_inspired_reasoning import QuantumInspiredReasoningState


def test_meta_polytope_matrioshka():
    """Test Meta-Polytope Matrioshka system"""
    print("ğŸ”® Testing Meta-Polytope Matrioshka System...")
    
    try:
        # Initialize system
        matrioshka = MetaPolytopeMatrioshka(max_depth=3, base_dim=64)
        
        # Test input
        batch_size = 4
        x = torch.randn(batch_size, 64) * 0.5
        
        print(f"   Input shape: {x.shape}")
        print(f"   Input range: [{x.min():.3f}, {x.max():.3f}]")
        
        # Test forward pass
        result, new_alpha, new_level = matrioshka(x, alpha=0, level=0)
        
        print(f"   Output shape: {result.shape}")
        print(f"   Output range: [{result.min():.3f}, {result.max():.3f}]")
        print(f"   New alpha: {new_alpha}, New level: {new_level}")
        
        # Test NaN handling
        nan_input = torch.full((2, 64), float('nan'))
        nan_result, _, _ = matrioshka(nan_input, alpha=1, level=1)
        
        print(f"   NaN handling: {torch.isnan(nan_result).sum().item()} NaN values")
        
        # Test computational efficiency
        import time
        start_time = time.time()
        
        for _ in range(10):
            _ = matrioshka(x, alpha=0, level=0)
            
        elapsed = time.time() - start_time
        print(f"   Performance: {elapsed/10:.4f}s per forward pass")
        
        # Test CRT system
        crt_info = matrioshka.crt_system
        print(f"   CRT moduli: {crt_info['moduli']}")
        print(f"   CRT space size: {crt_info['total_space']}")
        
        print("   âœ… Meta-Polytope Matrioshka system working!")
        return True
        
    except Exception as e:
        print(f"   âŒ Meta-Polytope Matrioshka failed: {e}")
        return False


def test_sparse_higher_order_tensors():
    """Test Sparse Higher-Order Tensor Dynamics"""
    print("\nğŸ¯ Testing Sparse Higher-Order Tensor Dynamics...")
    
    try:
        # Initialize system
        tensor_system = SparseHigherOrderTensorDynamics(max_order=3, num_shells=3, base_dim=64)
        
        # Test input
        batch_size = 4
        x = torch.randn(batch_size, 64) * 0.5
        
        print(f"   Input shape: {x.shape}")
        
        # Test with auto-detected active facets
        results = tensor_system(x)
        
        print(f"   Computed tensor orders: {list(results.keys())}")
        
        for order, tensor in results.items():
            print(f"   Order {order} shape: {tensor.shape}")
            print(f"   Order {order} range: [{tensor.min():.3f}, {tensor.max():.3f}]")
            
        # Test with specified active facets
        active_facets = [0, 5, 10, 15, 20]  # Sparse selection
        sparse_results = tensor_system(x, active_facets=active_facets)
        
        print(f"   Sparse computation orders: {list(sparse_results.keys())}")
        
        # Test computational savings
        savings = tensor_system.compute_computational_savings(x, active_facets)
        
        print(f"   Computational savings:")
        for metric, value in savings.items():
            if 'speedup' in metric:
                print(f"     {metric}: {value:.2f}x")
            else:
                print(f"     {metric}: {value:.4f}")
                
        # Test performance
        import time
        start_time = time.time()
        
        for _ in range(10):
            _ = tensor_system(x, active_facets=active_facets)
            
        elapsed = time.time() - start_time
        print(f"   Performance: {elapsed/10:.4f}s per forward pass")
        
        print("   âœ… Sparse Higher-Order Tensor Dynamics working!")
        return True
        
    except Exception as e:
        print(f"   âŒ Sparse Higher-Order Tensor Dynamics failed: {e}")
        return False


def test_quantum_inspired_reasoning():
    """Test Quantum-Inspired Reasoning State"""
    print("\nâš›ï¸  Testing Quantum-Inspired Reasoning State...")
    
    try:
        # Initialize system
        quantum_reasoner = QuantumInspiredReasoningState(dim=32)
        
        print(f"   Quantum state dimension: {quantum_reasoner.dim}")
        print(f"   Initial amplitude norm: {torch.norm(quantum_reasoner.amplitude):.6f}")
        
        # Test superposition reasoning
        hypotheses = [
            torch.randn(32) * 0.5,
            torch.randn(32) * 0.3,
            torch.randn(32) * 0.7
        ]
        
        print(f"   Number of hypotheses: {len(hypotheses)}")
        
        probabilities = quantum_reasoner.superposition_reasoning(hypotheses)
        
        print(f"   Probability shape: {probabilities.shape}")
        print(f"   Probability sum: {probabilities.sum():.6f}")
        print(f"   Probability range: [{probabilities.min():.6f}, {probabilities.max():.6f}]")
        
        # Test concept entanglement
        concept_a = torch.randn(16) * 0.5
        concept_b = torch.randn(16) * 0.3
        
        entangled = quantum_reasoner.entangle_concepts(concept_a, concept_b)
        
        print(f"   Entangled state shape: {entangled.shape}")
        print(f"   Entanglement norm: {torch.norm(entangled):.6f}")
        
        # Test quantum measurement
        test_state = torch.complex(torch.randn(32), torch.randn(32))
        test_state = test_state / torch.norm(test_state)
        
        expectation, collapsed = quantum_reasoner.quantum_measurement(test_state)
        
        print(f"   Measurement expectation: {expectation:.6f}")
        print(f"   Collapsed state norm: {torch.norm(collapsed):.6f}")
        
        # Test decoherence
        decoherent = quantum_reasoner.decoherence_model(test_state, noise_strength=0.1)
        
        print(f"   Decoherent state norm: {torch.norm(decoherent):.6f}")
        
        # Test quantum interference
        state_a = torch.complex(torch.randn(32), torch.randn(32))
        state_b = torch.complex(torch.randn(32), torch.randn(32))
        state_a = state_a / torch.norm(state_a)
        state_b = state_b / torch.norm(state_b)
        
        interference = quantum_reasoner.quantum_interference(state_a, state_b, phase_shift=np.pi/4)
        
        print(f"   Interference state norm: {torch.norm(interference):.6f}")
        
        # Test Hamiltonian update
        gradient = torch.randn(32, 32) * 0.01
        quantum_reasoner.update_hamiltonian(gradient, learning_rate=0.001)
        
        # Verify Hamiltonian is still Hermitian
        H = quantum_reasoner.reasoning_hamiltonian
        hermitian_error = torch.norm(H - H.T)
        print(f"   Hamiltonian Hermitian error: {hermitian_error:.8f}")
        
        print("   âœ… Quantum-Inspired Reasoning State working!")
        return True
        
    except Exception as e:
        print(f"   âŒ Quantum-Inspired Reasoning State failed: {e}")
        return False


def test_integration():
    """Test integration between systems"""
    print("\nğŸ”— Testing System Integration...")
    
    try:
        # Initialize all systems
        matrioshka = MetaPolytopeMatrioshka(max_depth=2, base_dim=32)
        tensor_system = SparseHigherOrderTensorDynamics(max_order=2, num_shells=2, base_dim=32)
        quantum_reasoner = QuantumInspiredReasoningState(dim=32)
        
        # Test data flow
        x = torch.randn(2, 32) * 0.3
        
        # Step 1: Meta-Polytope processing
        polytope_result, alpha, level = matrioshka(x)
        print(f"   Polytope result shape: {polytope_result.shape}")
        
        # Step 2: Higher-order tensor analysis
        tensor_results = tensor_system(polytope_result)
        print(f"   Tensor orders computed: {list(tensor_results.keys())}")
        
        # Step 3: Quantum superposition of tensor results
        if tensor_results:
            tensor_hypotheses = [tensor_results[order] for order in sorted(tensor_results.keys())]
            
            # Ensure all hypotheses have same dimension
            min_dim = min(h.shape[-1] for h in tensor_hypotheses)
            tensor_hypotheses = [h[..., :min_dim] for h in tensor_hypotheses]
            
            quantum_probs = quantum_reasoner.superposition_reasoning(tensor_hypotheses)
            print(f"   Quantum probabilities shape: {quantum_probs.shape}")
            print(f"   Integration probability sum: {quantum_probs.sum():.6f}")
        else:
            # Fallback: create dummy hypotheses for testing
            print("   No tensor results, using fallback hypotheses")
            dummy_hypotheses = [
                torch.randn(2, 16) * 0.3,
                torch.randn(2, 16) * 0.2,
                torch.randn(2, 16) * 0.4
            ]
            quantum_probs = quantum_reasoner.superposition_reasoning(dummy_hypotheses)
            print(f"   Fallback quantum probabilities shape: {quantum_probs.shape}")
            print(f"   Fallback integration probability sum: {quantum_probs.sum():.6f}")
        
        # Test computational efficiency of integrated system
        import time
        start_time = time.time()
        
        for _ in range(5):
            poly_out, _, _ = matrioshka(x)
            tensor_out = tensor_system(poly_out)
            if tensor_out:
                hypotheses = [tensor_out[order] for order in sorted(tensor_out.keys())]
                if hypotheses:  # Check if we have any hypotheses
                    min_dim = min(h.shape[-1] for h in hypotheses)
                    hypotheses = [h[..., :min_dim] for h in hypotheses]
                    _ = quantum_reasoner.superposition_reasoning(hypotheses)
            else:
                # Fallback for empty tensor results
                dummy_hypotheses = [torch.randn(2, 16) * 0.1]
                _ = quantum_reasoner.superposition_reasoning(dummy_hypotheses)
                
        elapsed = time.time() - start_time
        print(f"   Integrated system performance: {elapsed/5:.4f}s per pass")
        
        print("   âœ… System integration working!")
        return True
        
    except Exception as e:
        print(f"   âŒ System integration failed: {e}")
        return False


def test_efficiency_constraints():
    """Test efficiency constraints and computational limits"""
    print("\nâš¡ Testing Efficiency Constraints...")
    
    try:
        # Test memory efficiency
        import psutil
        import gc
        
        process = psutil.Process()
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB
        
        # Create larger systems to test memory usage
        large_matrioshka = MetaPolytopeMatrioshka(max_depth=3, base_dim=256)
        large_tensor_system = SparseHigherOrderTensorDynamics(max_order=3, num_shells=3, base_dim=256)
        large_quantum = QuantumInspiredReasoningState(dim=256)
        
        current_memory = process.memory_info().rss / 1024 / 1024  # MB
        memory_usage = current_memory - initial_memory
        
        print(f"   Memory usage for large systems: {memory_usage:.1f} MB")
        
        # Test computational scaling
        batch_sizes = [1, 2, 4, 8]
        times = []
        
        for batch_size in batch_sizes:
            x = torch.randn(batch_size, 256) * 0.3
            
            start_time = time.time()
            
            # Run integrated pipeline
            poly_out, _, _ = large_matrioshka(x)
            tensor_out = large_tensor_system(poly_out, active_facets=list(range(0, 256, 10)))  # Sparse
            
            if tensor_out:
                hypotheses = [tensor_out[order] for order in sorted(tensor_out.keys())]
                min_dim = min(h.shape[-1] for h in hypotheses)
                hypotheses = [h[..., :min_dim] for h in hypotheses]
                _ = large_quantum.superposition_reasoning(hypotheses)
                
            elapsed = time.time() - start_time
            times.append(elapsed)
            
        print(f"   Computational scaling:")
        for i, (batch_size, time_taken) in enumerate(zip(batch_sizes, times)):
            print(f"     Batch {batch_size}: {time_taken:.4f}s")
            if i > 0 and times[0] > 0:
                scaling_factor = times[i] / times[0]
                efficiency = batch_size / scaling_factor
                print(f"       Efficiency: {efficiency:.2f}x")
            elif i > 0:
                print(f"       Efficiency: N/A (baseline time too small)")
                
        # Test sparse vs dense comparison
        dense_facets = list(range(256))
        sparse_facets = list(range(0, 256, 8))  # Every 8th facet
        
        x_test = torch.randn(4, 256) * 0.3
        
        start_time = time.time()
        dense_result = large_tensor_system(x_test, active_facets=dense_facets)
        dense_time = time.time() - start_time
        
        start_time = time.time()
        sparse_result = large_tensor_system(x_test, active_facets=sparse_facets)
        sparse_time = time.time() - start_time
        
        speedup = dense_time / sparse_time if sparse_time > 0 else float('inf')
        
        print(f"   Sparse vs Dense computation:")
        print(f"     Dense facets: {len(dense_facets)}, Time: {dense_time:.4f}s")
        print(f"     Sparse facets: {len(sparse_facets)}, Time: {sparse_time:.4f}s")
        print(f"     Speedup: {speedup:.2f}x")
        
        # Cleanup
        del large_matrioshka, large_tensor_system, large_quantum
        gc.collect()
        
        final_memory = process.memory_info().rss / 1024 / 1024  # MB
        memory_freed = current_memory - final_memory
        
        print(f"   Memory freed after cleanup: {memory_freed:.1f} MB")
        
        print("   âœ… Efficiency constraints satisfied!")
        return True
        
    except Exception as e:
        print(f"   âŒ Efficiency constraint testing failed: {e}")
        return False


def main():
    """Run all tests"""
    print("ğŸ§ª Testing Advanced Mathematical Extensions")
    print("=" * 60)
    
    tests = [
        test_meta_polytope_matrioshka,
        test_sparse_higher_order_tensors,
        test_quantum_inspired_reasoning,
        test_integration,
        test_efficiency_constraints
    ]
    
    results = []
    
    for test in tests:
        try:
            result = test()
            results.append(result)
        except Exception as e:
            print(f"   âŒ Test failed with exception: {e}")
            results.append(False)
            
    print("\n" + "=" * 60)
    print("ğŸ“Š Test Summary:")
    
    passed = sum(results)
    total = len(results)
    
    print(f"   Passed: {passed}/{total}")
    print(f"   Success rate: {passed/total*100:.1f}%")
    
    if passed == total:
        print("   ğŸ‰ All advanced extensions working correctly!")
        print("   âœ… Ready for production use")
    else:
        print("   âš ï¸  Some tests failed - review implementations")
        
    return passed == total


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
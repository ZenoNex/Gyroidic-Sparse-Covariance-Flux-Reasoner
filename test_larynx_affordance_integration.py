#!/usr/bin/env python3
"""
Test ResonanceLarynx integration with affordance gradients and conversational coherence.
Verifies that the synthetic larynx is properly connected to all appropriate systems.
"""

import torch
import torch.nn.functional as F
import numpy as np
from typing import Dict, List, Optional, Tuple

# Import core components
from src.models.diegetic_heads import ResonanceLarynx, DataAssociationLayer
from src.models.resonance_cavity import ResonanceCavity
from src.core.spectral_coherence_repair import SpectralCoherenceCorrector
from fix_conversational_coherence_proper import ProperConversationalCoherenceFix

class LarynxAffordanceIntegrationTest:
    """
    Comprehensive test of ResonanceLarynx integration with affordance systems.
    """
    
    def __init__(self, device = 'cuda' if torch.cuda.is_available() else 'cpu' if torch.cuda.is_available() else 'cpu'):
        self.device = device
        self.dim = 64
        
        # Initialize core components
        self.larynx = ResonanceLarynx(hidden_dim=self.dim, vocab_size=128)
        self.cavity = ResonanceCavity(hidden_dim=self.dim, num_modes=16)
        self.spectral_corrector = SpectralCoherenceCorrector(device=device)
        self.conversational_fix = ProperConversationalCoherenceFix(device=device)
        
        # Initialize with some conversational training
        self._setup_conversational_training()
        
    def _setup_conversational_training(self):
        """Setup conversational training data for the coherence fix system."""
        
        # Create realistic conversational training data
        mock_conversations = []
        
        conversation_patterns = [
            {'conv_pressure': 0.85, 'api': 0.01, 'formal': 0.005, 'exec': 0.02},
            {'conv_pressure': 0.78, 'api': 0.03, 'formal': 0.01, 'exec': 0.025},
            {'conv_pressure': 0.82, 'api': 0.02, 'formal': 0.008, 'exec': 0.015},
        ]
        
        for i, pattern in enumerate(conversation_patterns * 5):
            mock_turn = type('Turn', (), {
                'text': f'Conversational example {i}',
                'affordance_gradients': {
                    'conversational_embedding_pressure': pattern['conv_pressure'] + 0.05 * np.random.randn(),
                    'api_extraction_potential': pattern['api'] + 0.01 * np.random.rand(),
                    'formal_symbols': pattern['formal'] + 0.005 * np.random.rand(),
                    'executability': pattern['exec'] + 0.01 * np.random.rand()
                }
            })()
            
            mock_conv = type('Conversation', (), {'turns': [mock_turn]})()
            mock_conversations.append(mock_conv)
        
        # Train the conversational fix system
        self.conversational_fix.learn_from_conversational_data(mock_conversations)
    
    def compute_affordance_gradients(self, text: str) -> Dict[str, float]:
        """
        Compute affordance gradients for input text.
        Simulates the actual affordance computation system.
        """
        
        # Basic heuristics for affordance computation
        affordances = {}
        
        # Conversational embedding pressure
        conversational_indicators = ['hello', 'how', 'you', 'please', 'thank', 'sorry', 'yes', 'no']
        conv_score = sum(1 for word in conversational_indicators if word.lower() in text.lower())
        affordances['conversational_embedding_pressure'] = min(conv_score / 5.0, 1.0)
        
        # API extraction potential
        api_indicators = ['function', 'method', 'class', 'import', 'return', 'def', 'api', 'call']
        api_score = sum(1 for word in api_indicators if word.lower() in text.lower())
        affordances['api_extraction_potential'] = min(api_score / 3.0, 1.0)
        
        # Formal symbols
        formal_chars = sum(1 for c in text if c in '(){}[]+=*/<>|&^%$#@!')
        affordances['formal_symbols'] = min(formal_chars / len(text), 1.0) if text else 0.0
        
        # Executability
        exec_indicators = ['run', 'execute', 'compute', 'calculate', 'process', 'generate']
        exec_score = sum(1 for word in exec_indicators if word.lower() in text.lower())
        affordances['executability'] = min(exec_score / 3.0, 1.0)
        
        return affordances
    
    def test_larynx_basic_functionality(self):
        """Test basic ResonanceLarynx functionality."""
        
        print("üß™ Testing ResonanceLarynx Basic Functionality")
        print("-" * 50)
        
        # Test forward pass
        batch_size = 4
        state = torch.randn(batch_size, self.dim)
        
        logits, confidence = self.larynx(state, temperature=1.0)
        
        print(f"   ‚úÖ Forward pass successful")
        print(f"      ‚Ä¢ Input shape: {state.shape}")
        print(f"      ‚Ä¢ Logits shape: {logits.shape}")
        print(f"      ‚Ä¢ Confidence shape: {confidence.shape}")
        print(f"      ‚Ä¢ Confidence range: [{confidence.min():.3f}, {confidence.max():.3f}]")
        
        # Test character generation
        probs = F.softmax(logits, dim=-1)
        sampled_chars = torch.multinomial(probs, 1).squeeze(-1)
        
        # Convert to ASCII characters
        generated_text = ''.join([chr(min(max(c.item(), 32), 126)) for c in sampled_chars])
        print(f"      ‚Ä¢ Generated text sample: '{generated_text}'")
        
        # Test Hebbian learning
        print(f"\n   üß† Testing Hebbian Learning...")
        
        # Create one-hot targets
        target_chars = torch.randint(32, 127, (batch_size,))  # Printable ASCII
        target_onehot = F.one_hot(target_chars, num_classes=128).float()
        
        # Store original weights
        original_weights = self.larynx.proj.weight.clone()
        
        # Apply Hebbian update
        self.larynx.hebbian_update(state, target_onehot, rate=0.1)
        
        # Check weight change
        weight_change = torch.norm(self.larynx.proj.weight - original_weights).item()
        print(f"      ‚Ä¢ Weight change magnitude: {weight_change:.6f}")
        print(f"      ‚Ä¢ Hebbian learning: {'‚úÖ Active' if weight_change > 1e-6 else '‚ùå Inactive'}")
        
        return True
    
    def test_cavity_larynx_integration(self):
        """Test integration between ResonanceCavity and ResonanceLarynx."""
        
        print(f"\nüîó Testing Cavity-Larynx Integration")
        print("-" * 50)
        
        # Generate cavity state
        batch_size = 2
        input_signal = torch.randn(batch_size, self.dim)
        
        # Process through cavity
        # ResonanceCavity expects attention_states with shape [batch, seq_len, hidden_dim]
        input_signal_expanded = input_signal.unsqueeze(1)  # Add seq_len dimension
        cavity_result = self.cavity(input_signal_expanded)
        cavity_output = cavity_result['memory_state'][:, 0, :]  # Take first mode
        print(f"   ‚úÖ Cavity processing successful")
        print(f"      ‚Ä¢ Cavity output shape: {cavity_output.shape}")
        
        # Process cavity output through larynx
        logits, confidence = self.larynx(cavity_output)
        
        # Generate text from cavity state
        probs = F.softmax(logits, dim=-1)
        sampled_chars = torch.multinomial(probs, 1).squeeze(-1)
        generated_texts = []
        
        for i in range(batch_size):
            text = ''.join([chr(min(max(c.item(), 32), 126)) for c in sampled_chars[i:i+1]])
            generated_texts.append(text)
        
        print(f"   ‚úÖ Cavity‚ÜíLarynx pipeline successful")
        print(f"      ‚Ä¢ Generated from cavity states:")
        for i, text in enumerate(generated_texts):
            print(f"        [{i}]: '{text}'")
        
        return True
    
    def test_affordance_larynx_integration(self):
        """Test integration between affordance gradients and larynx output."""
        
        print(f"\nüéØ Testing Affordance-Larynx Integration")
        print("-" * 50)
        
        test_inputs = [
            "Hello, how are you doing today?",
            "def process_data(input_list): return [x*2 for x in input_list]",
            "Calculate the derivative of f(x) = x^2 + 3x - 5",
            "The system creates recursive meta-structures that reference themselves."
        ]
        
        for i, text_input in enumerate(test_inputs):
            print(f"\n   Test {i+1}: {text_input[:40]}...")
            
            # Compute affordance gradients
            affordances = self.compute_affordance_gradients(text_input)
            print(f"      ‚Ä¢ Affordances computed:")
            for key, value in affordances.items():
                print(f"        - {key}: {value:.3f}")
            
            # Create state representation from text
            text_hash = hash(text_input) % (2**31)
            torch.manual_seed(text_hash)
            text_state = torch.randn(1, self.dim)
            
            # Process through larynx
            logits, confidence = self.larynx(text_state)
            
            # Check if conversational coherence fix should be applied
            conv_likelihood = self.conversational_fix.detect_conversational_input_proper(affordances)
            print(f"      ‚Ä¢ Conversational likelihood: {conv_likelihood:.3f}")
            
            # Apply conversational fix if needed
            if conv_likelihood > 0.3:
                print(f"      ‚Ä¢ Applying conversational coherence fix...")
                fixed_state = self.conversational_fix.fix_conversational_garbling(text_state, affordances)
                fixed_logits, fixed_confidence = self.larynx(fixed_state)
                
                # Compare original vs fixed
                original_entropy = -torch.sum(F.softmax(logits, dim=-1) * F.log_softmax(logits, dim=-1), dim=-1).mean()
                fixed_entropy = -torch.sum(F.softmax(fixed_logits, dim=-1) * F.log_softmax(fixed_logits, dim=-1), dim=-1).mean()
                
                print(f"        - Original entropy: {original_entropy:.3f}")
                print(f"        - Fixed entropy: {fixed_entropy:.3f}")
                print(f"        - Entropy change: {(fixed_entropy - original_entropy):.3f}")
            else:
                print(f"      ‚Ä¢ No conversational fix needed")
        
        return True
    
    def test_spectral_coherence_integration(self):
        """Test integration with spectral coherence correction."""
        
        print(f"\nüåä Testing Spectral Coherence Integration")
        print("-" * 50)
        
        # Create garbled larynx output
        batch_size = 3
        garbled_state = torch.randn(batch_size, self.dim) * 2.0  # High variance = garbled
        
        print(f"   Creating garbled larynx output...")
        original_logits, original_confidence = self.larynx(garbled_state)
        
        # Apply spectral coherence correction
        print(f"   Applying spectral coherence correction...")
        corrected_state = self.spectral_corrector.adaptive_coherence_correction(garbled_state)
        corrected_logits, corrected_confidence = self.larynx(corrected_state)
        
        # Analyze correction effectiveness
        original_var = torch.var(garbled_state, dim=-1).mean().item()
        corrected_var = torch.var(corrected_state, dim=-1).mean().item()
        
        original_conf_mean = original_confidence.mean().item()
        corrected_conf_mean = corrected_confidence.mean().item()
        
        print(f"   ‚úÖ Spectral correction applied:")
        print(f"      ‚Ä¢ Original state variance: {original_var:.4f}")
        print(f"      ‚Ä¢ Corrected state variance: {corrected_var:.4f}")
        print(f"      ‚Ä¢ Variance reduction: {(original_var - corrected_var) / original_var * 100:.1f}%")
        print(f"      ‚Ä¢ Original confidence: {original_conf_mean:.3f}")
        print(f"      ‚Ä¢ Corrected confidence: {corrected_conf_mean:.3f}")
        print(f"      ‚Ä¢ Confidence change: {(corrected_conf_mean - original_conf_mean):.3f}")
        
        return True
    
    def test_end_to_end_pipeline(self):
        """Test complete end-to-end pipeline with all systems integrated."""
        
        print(f"\nüöÄ Testing End-to-End Pipeline")
        print("-" * 50)
        
        test_scenarios = [
            {
                'name': 'Conversational Input',
                'text': 'Hi there! How can I help you today?',
                'expected_flow': 'Input ‚Üí Affordances ‚Üí Conversational Fix ‚Üí Larynx ‚Üí Output'
            },
            {
                'name': 'Code Input',
                'text': 'def fibonacci(n): return n if n <= 1 else fibonacci(n-1) + fibonacci(n-2)',
                'expected_flow': 'Input ‚Üí Affordances ‚Üí Spectral Correction ‚Üí Larynx ‚Üí Output'
            },
            {
                'name': 'Mixed Input',
                'text': 'Here is a function: lambda x: x**2. What do you think?',
                'expected_flow': 'Input ‚Üí Affordances ‚Üí Conditional Processing ‚Üí Larynx ‚Üí Output'
            }
        ]
        
        for scenario in test_scenarios:
            print(f"\n   üé¨ Scenario: {scenario['name']}")
            print(f"      Input: {scenario['text']}")
            print(f"      Expected: {scenario['expected_flow']}")
            
            # Step 1: Compute affordances
            affordances = self.compute_affordance_gradients(scenario['text'])
            print(f"      Step 1 - Affordances: ‚úÖ")
            
            # Step 2: Create initial state
            text_hash = hash(scenario['text']) % (2**31)
            torch.manual_seed(text_hash)
            initial_state = torch.randn(1, self.dim)
            
            # Step 3: Process through cavity (resonance)
            initial_state_expanded = initial_state.unsqueeze(1)  # Add seq_len dimension
            cavity_result = self.cavity(initial_state_expanded)
            resonant_state = cavity_result['memory_state'][:, 0, :]  # Take first mode
            print(f"      Step 2 - Resonance: ‚úÖ")
            
            # Step 4: Apply appropriate corrections
            conv_likelihood = self.conversational_fix.detect_conversational_input_proper(affordances)
            
            if conv_likelihood > 0.3:
                # Apply conversational fix
                processed_state = self.conversational_fix.fix_conversational_garbling(resonant_state, affordances)
                correction_type = "Conversational"
            else:
                # Apply spectral correction
                processed_state = self.spectral_corrector.adaptive_coherence_correction(resonant_state)
                correction_type = "Spectral"
            
            print(f"      Step 3 - {correction_type} Correction: ‚úÖ")
            
            # Step 5: Generate output through larynx
            final_logits, final_confidence = self.larynx(processed_state)
            
            # Generate sample output
            probs = F.softmax(final_logits, dim=-1)  # [batch, vocab_size]
            if probs.dim() > 2:
                probs = probs.squeeze()
            if probs.dim() == 1:
                probs = probs.unsqueeze(0)
            
            # Sample one character at a time to build output
            output_chars = []
            for _ in range(8):
                char_idx = torch.multinomial(probs[0], 1).item()
                output_chars.append(chr(min(max(char_idx, 32), 126)))
            output_text = ''.join(output_chars)
            
            print(f"      Step 4 - Larynx Output: ‚úÖ")
            print(f"      Final Output: '{output_text}'")
            print(f"      Confidence: {final_confidence.mean().item():.3f}")
            print(f"      Pipeline: {'‚úÖ Complete' if len(output_text) > 0 else '‚ùå Failed'}")
        
        return True
    
    def run_all_tests(self):
        """Run all integration tests."""
        
        print("üß™ ResonanceLarynx Affordance Integration Test Suite")
        print("=" * 60)
        
        tests = [
            self.test_larynx_basic_functionality,
            self.test_cavity_larynx_integration,
            self.test_affordance_larynx_integration,
            self.test_spectral_coherence_integration,
            self.test_end_to_end_pipeline
        ]
        
        passed = 0
        total = len(tests)
        
        for test in tests:
            try:
                result = test()
                if result:
                    passed += 1
            except Exception as e:
                print(f"   ‚ùå Test failed with error: {e}")
        
        print(f"\n" + "=" * 60)
        print(f"üéØ Test Results: {passed}/{total} tests passed")
        
        if passed == total:
            print("‚úÖ ALL SYSTEMS PROPERLY INTEGRATED!")
            print("‚úÖ ResonanceLarynx connected to all appropriate systems")
            print("‚úÖ Affordance gradients properly computed and applied")
            print("‚úÖ Conversational coherence fix integrated")
            print("‚úÖ Spectral coherence correction integrated")
            print("‚úÖ End-to-end pipeline functional")
        else:
            print("‚ö†Ô∏è  Some integration issues detected")
        
        print("=" * 60)
        
        return passed == total

def main():
    """Run the larynx affordance integration tests."""
    
    tester = LarynxAffordanceIntegrationTest()
    success = tester.run_all_tests()
    
    if success:
        print("\nüéâ ResonanceLarynx integration verification complete!")
        print("üîó All systems properly connected and functional")
    else:
        print("\n‚ö†Ô∏è  Integration issues detected - check test output")
    
    return success

if __name__ == "__main__":
    main()
